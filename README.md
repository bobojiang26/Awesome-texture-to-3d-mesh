# Awesome-texture-to-3d-mesh

2023:

TEXTure: Text-Guided Texturing of 3D Shapes[[pdf]](https://arxiv.org/abs/2302.01721)
[[code]](https://github.com/TEXTurePaper/TEXTurePaper)

Text2Tex: Text-driven Texture Synthesis via Diffusion Models[[pdf]](https://arxiv.org/abs/2303.11396)
[[code]](https://github.com/daveredrum/Text2Tex)

Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures[[pdf]](https://arxiv.org/abs/2211.07600)
[[code]](https://github.com/eladrich/latent-nerf)

Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models[[pdf]](https://arxiv.org/abs/2212.14704)

2022:

TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition[[pdf]](https://arxiv.org/abs/2210.11277)
[[code]](https://github.com/Gorilla-Lab-SCUT/tango)

CLIP-Mesh: Generating textured meshes from text using pretrained image-text models[[pdf]](https://arxiv.org/abs/2203.13333)
[[code]](https://github.com/NasirKhalid24/CLIP-Mesh)

Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures.[[pdf]](https://arxiv.org/abs/2211.07600)
[[code]](https://github.com/eladrich/latent-nerf)

Magic3D: High-Resolution Text-to-3D Content Creation.[[pdf]](https://arxiv.org/abs/2211.10440)
[[code]](https://github.com/chinhsuanwu/dreamfusionacc)

2021:

Text2Mesh: Text-Driven Neural Stylization for Meshes[[pdf]](https://arxiv.org/abs/2112.03221)
[[code]](https://github.com/threedle/text2mesh)

2020:

Deep Geometric Texture Synthesis.[[pdf]](https://arxiv.org/pdf/2007.00074.pdf)


2017:
Learning Detail Transfer based on Geometric Features.[[pdf]](https://diglib.eg.org/xmlui/bitstream/handle/10.1111/cgf13132/v36i2pp361-373.pdf?sequence=1&isAllowed=y)

2012:
Non-parametric Texture Transfer Using MeshMatch.[[pdf]](https://danbgoldman.com/misc/meshmatch/meshmatch.pdf)
