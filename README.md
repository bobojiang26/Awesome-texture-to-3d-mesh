# Awesome-texture-to-3d-mesh

2024:

Decorate3D: Text-Driven High-Quality Texture Generation for Mesh Decoration in the Wild[[pdf]](https://decorate3d.github.io/Decorate3D/static/Decorate3D.pdf)
[[code]](https://github.com/Decorate3D/Decorate3D)

Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering[[pdf]](https://kim-youwang.github.io/media/paint-it/paint-it.pdf)
[[code]](https://github.com/postech-ami/paint-it)

TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion[[pdf]](https://arxiv.org/pdf/2401.09416.pdf)

HexaGen3D: StableDiffusion is just one step away from Fast and Diverse Text-to-3D Generation[[pdf]](https://arxiv.org/pdf/2401.07727.pdf)

Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior[[pdf]](https://liuff19.github.io/Sherpa3D/static/pdfs/Sherpa3D_paper.pdf)
[[code]](https://github.com/liuff19/Sherpa3D)

Interactive Text-to-texture Synthesis via Unified Depth-aware Inpainting[[pdf]](https://arxiv.org/pdf/2403.11878.pdf)
[[code]](https://github.com/ashawkey/InTeX)

FlashTex: Fast Relightable Mesh Texturing with LightControlNet[[pdf]](https://arxiv.org/pdf/2402.13251.pdf)

TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation[[pdf]](https://arxiv.org/pdf/2403.12906.pdf)
[[code]](https://github.com/ggxxii/texdreamer)

Single Mesh Diffusion Models with Field Latents for Texture Generation[[pdf]](https://arxiv.org/pdf/2312.09250.pdf)
[[code]](https://github.com/google-research/google-research/tree/master/mesh_diffusion)

CTGAN: Semantic-guided Conditional Texture Generator for 3D Shapes[pdf](https://arxiv.org/pdf/2402.05728.pdf)

ControlDreamer: Stylized 3D Generation with Multi-View ControlNet[[pdf]](https://arxiv.org/pdf/2312.01129.pdf)

2023:

TEXTure: Text-Guided Texturing of 3D Shapes[[pdf]](https://arxiv.org/abs/2302.01721)
[[code]](https://github.com/TEXTurePaper/TEXTurePaper)

Text2Tex: Text-driven Texture Synthesis via Diffusion Models[[pdf]](https://arxiv.org/abs/2303.11396)
[[code]](https://github.com/daveredrum/Text2Tex)

Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures[[pdf]](https://arxiv.org/abs/2211.07600)
[[code]](https://github.com/eladrich/latent-nerf)

Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models[[pdf]](https://arxiv.org/abs/2212.14704)

TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models[[pdf]](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf)

Breathing New Life into 3D Assets with Generative Repainting[[pdf]](https://arxiv.org/pdf/2309.08523.pdf)
[[code]](https://github.com/kongdai123/repainting_3d_assets)

Text-Guided Texturing by Synchronized Multi-View Diffusion[[pdf]](https://arxiv.org/pdf/2311.12891.pdf)

Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models[[pdf]](https://arxiv.org/pdf/2312.13913.pdf)
[[code]](https://github.com/OpenTexture/Paint3D)

PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation[[pdf]](https://arxiv.org/pdf/2310.09458.pdf)

DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaption by Combining 3D GANs and Diffusion Priors[[pdf]](https://arxiv.org/pdf/2312.16837.pdf)
[[code]](https://github.com/youngLBW/DiffusionGAN3D)

Disentangled Clothed Avatar Generation from Text Descriptions[[pdf]](https://arxiv.org/pdf/2312.05295.pdf)
[[code]](https://github.com/shanemankiw/so-smpl)


2022:

TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition[[pdf]](https://arxiv.org/abs/2210.11277)
[[code]](https://github.com/Gorilla-Lab-SCUT/tango)

CLIP-Mesh: Generating textured meshes from text using pretrained image-text models[[pdf]](https://arxiv.org/abs/2203.13333)
[[code]](https://github.com/NasirKhalid24/CLIP-Mesh)


Magic3D: High-Resolution Text-to-3D Content Creation.[[pdf]](https://arxiv.org/abs/2211.10440)
[[code]](https://github.com/chinhsuanwu/dreamfusionacc)

SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained Geometry and Appearance[[pdf]](https://arxiv.org/pdf/2312.08889.pdf)
[[code]](https://github.com/yoxu515/SEEAvatar)

2021:

Text2Mesh: Text-Driven Neural Stylization for Meshes[[pdf]](https://arxiv.org/abs/2112.03221)
[[code]](https://github.com/threedle/text2mesh)

2020:

Deep Geometric Texture Synthesis.[[pdf]](https://arxiv.org/pdf/2007.00074.pdf)


2017:

Learning Detail Transfer based on Geometric Features.[[pdf]](https://diglib.eg.org/xmlui/bitstream/handle/10.1111/cgf13132/v36i2pp361-373.pdf?sequence=1&isAllowed=y)

2012:

Non-parametric Texture Transfer Using MeshMatch.[[pdf]](https://danbgoldman.com/misc/meshmatch/meshmatch.pdf)


<br><br>

**Testset:**

Concept Combination:[Wagon dog](https://sketchfab.com/3d-models/wagon-dog-0a4a4bbc0d9b4425aa7dee8b0e50fc4a)

Animal:[Lion](https://sketchfab.com/3d-models/lion-f94d39b60c5846148b63b523c8e85ed4)

Furniture:[Modern sofa](https://sketchfab.com/3d-models/modern-sofa-ac92f6e97eaa43c4ad6cb8f7c65ac43f)

Game character:[Demon hunter](https://sketchfab.com/3d-models/demon-hunter-ff6a14371bc347d9a1526f5e64b29327)

Realistic human body:[Scan human](https://sketchfab.com/3d-models/3d-scan-man-1-ad42febfaeb64aa0992e804acc9e7ccd)

Building:[Futuristic building](https://sketchfab.com/3d-models/futuristic-building-e73f9bb9981d469c8a8ccdc1f168faad)


<br><br>
**Experiments**

[Google Doc](https://docs.google.com/document/d/19jMw7_09a0VxJVR-vOGbm0YV_f9e1ml9o94QcVnDBv8/edit?usp=sharing)

More experiment results can be found here:

[Google Drive](https://drive.google.com/drive/folders/1XU_Zq2GsJjpLUufx5V9bQsUea8RK3raD?usp=sharing)

**Notes**

[Google Doc](https://docs.google.com/document/d/1PzV7qpY6EDzB1clKre63EyOy2BNNGdu7dIuz62p6zds/edit?usp=sharing)



